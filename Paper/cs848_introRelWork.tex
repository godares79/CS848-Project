\section{Introduction}

Recently, the cloud has attracted significant attention from both the scientific research community and practitioners. Long running, resource intensive tasks can be run on the cloud using as many nodes as required, thus greatly reducing the task completion time and eliminating the need to procure expensive server grade hardware~\cite{Agrawal:2008:CRD:1462571.1462573}. However, the performance of cloud compute nodes is often not consistent, with some nodes obtaining orders of magnitude worse performance than other nodes. There are a variety of reasons a node could suffer from degraded performance, ranging from extremely heavy workload (i.e., the node is a hotspot), to partial hardware failure~\cite{citeulike:6656195}. However, modern scheduling systems typically only assign a query to the closest replica~\cite{borthakur-07} without taking heterogeneous hardware into account. This limits communication between servers, and makes congestion and computation hot-spots prevalent even when spare capacity is available elsewhere.

In this paper we describe a resource based query assignment algorithm for distributed databases. The goal of our work is to explore an efficient way to schedule queries based on server conditions (e.g., resource usage, hardware condition and network traffic) in order to attain better performance and alleviate hotspots. We first start by considering CPU and memory usage information to assign queries.

The contributions of our paper are:

\begin{itemize}
\item We design and implement an algorithm for assigning queries to nodes in the database cluster based upon the CPU and Memory (RAM) usage of the nodes.
\item We implement our query assignment algorithm in the Apache Cassandra~\cite{ Lakshman:2010:CDS:1773912.1773922} open source distributed database project.
\item We ran a series experiments and found that our algorithm provides a benefit under certain circumstances.
\item We explore other factors that we feel are very important (e.g., disk seek time, distance between servers, and network traffic) for determining the execution time of a query. We take those factors into consideration and further develop a new formula that we believe would more closely resemble the resource requirements for executing a query.
\end{itemize}
 
The remainder of this paper is organized as follows. In Section~\ref{sec:relWork}, we describe several areas related work. Section~\ref{sec:design} and Section~\ref{sec:implementation} describe the design and implementation of our query assignment method. Section~\ref{sec:experiments} describes the experimental evaluation of our method and Section~\ref{sec:discussion} discusses the results of the experiments as well as some of our limitations and future work. Section~\ref{sec:conclusion} finishes with some concluding remarks.

\section{Related Work}
\label{sec:relWork}

There has been significant previous work on estimating workload resource usage in order to maximize performance and minimize the resources used~\cite{citeulike:6656217,5452742,curino2011relational, MIT-Relational}. These predict job execution time and resource requirements and can help cloud providers make decisions about where and when requests from users are to be executed~\cite{citeulike:6656217}. Many researchers have built workload placement recommendation services that are based on workload demand patterns~\cite{Gmach:2007:WAD:1524302.1524818, Atikoglu:2012:WAL:2254756.2254766}. Such an approach can result in a 35\% reduction in processor usage~\cite{Gmach:2007:WAD:1524302.1524818}. However, these are all time consuming offline methods -- whereas our system focuses on dynamically forwarding workload to the idlest server, in order to distribute the workload evenly and prevent hotspots.
 
There is also a significant amount of research with regards to database partitioning schemes. Graph partitioning algorithms~\cite{Karypis:1998:FHQ:305219.305248}, workload-aware partitioning~\cite{Scholl:2009:WDP:1516360.1516366}, and classical work on physical design and partitioning~\cite{Zilio:1998:PDD:928651} are focused on dividing data into partitions that maximize query performance and allow workloads to scale across multiple computing nodes. However, graph partitioning is an NP-hard problem, and solutions to this problem are generally derived using heuristics and approximation algorithms~\cite{citeulike:11192678}. These introduce significant execution complexity, and extremely variable performance among different databases. There has also been research on workload-aware partitioning which will partition tables based on workload prediction~\cite{Scholl:2009:WDP:1516360.1516366, Mit-Shinobi}; however, there are many potential workloads, a finite number can be hosted by each server, and each workload has capacity requirements that may frequently change based on business needs~\cite{Gmach:2007:WAD:1524302.1524818}. This means that workload-aware partitioning needs to be dynamic rather than static; however dynamic workload-aware partitioning reduces performance dramatically. Lastly, previous research on physical design and partitioning has created a method allowing both static and dynamic repartitioning of a database in order to increase I/O bandwidth~\cite{Zilio:1998:PDD:928651}. This approach is pragmatic, but if we only rely on partitioning the database then the performance will be limited. In general, offline partitioning of a database is complementary to our work and both methods could be used to together.
 
Virtual machine (VM) migration provides another approach for load balancing. VM migration focuses on the transfer of a VM from one physical machine to another with little to no service downtime when the server that the VM sits on becomes overloaded with processes, traffic, or memory usage~\cite{Clark:2005:LMV:1251203.1251223}. Nevertheless, the challenges of long distance live migration are WAN bandwidth, latency, and packet loss that are outside the control of most IT organizations. Many applications are susceptible to network issues across the WAN that can be exacerbated by distance and network quality~\cite{murphyVMWare}. In addition, traditional VM migration will cause network traffic and bandwidth consumption, and many VM migration researchers are struggling with mitigating those causes~\cite{Liu:2009:LMV:1551609.1551630}.
