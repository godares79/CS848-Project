\section{Introduction}

Recently, the cloud has attracted a lot of attention from both the scientific research community and practitioners as it enables executing long running resource intensive tasks on the cloud using as many nodes as required thus greatly reducing the task completion time and eliminating the need to procure expensive server grade hardware~\cite{Agrawal:2008:CRD:1462571.1462573}. However, the performance of cloud compute nodes is often not consistent, with some nodes obtaining orders of magnitude worse performance than other nodes. There are a variety of reasons a node could suffer from degraded performance, ranging from extremely heavy workload (i.e., the node is a hotspot), to partial hardware failure~\cite{citeulike:6656195}. However, the modern scheduling systems only simply assigned query to the closest replica~\cite{borthakur-07}, without taking heterogeneous hardware into account. This eventually limits communication between servers, and making congestion and computation hot-spots prevalent even when spare capacity is available elsewhere.

In this paper we describe a resource based query assignment algorithm for distributed databases. The goal of our work is to explore an efficient way to schedule queries based on server conditions, such as resource usage, hardware condition and network traffic in order to attain better performance and alleviate hotspots. We first start by using CPU and memory usage information to scheduling queries; however, due to time and environmental constraints, we have not explored the possibility of using other related resource usage. The contributions of our paper are the following. First, we implement our scheduling algorithm on the Apache Cassandra~\cite{ Lakshman:2010:CDS:1773912.1773922} open source distributed file project. Second, we implemented an algorithm for assigning queries to nodes based upon the CPU and Memory (RAM) usage of the nodes. Third, we ran a series experiments and found that our algorithm provides a benefit under certain circumstances. Finally, we found that other factors that we feel are very important (e.g., disk seek time, distance between servers, and network traffic) for our implementation. We take those factors into consideration and further develop a new formula that we believe would more closely resemble the resource requirements for executing a query.
 
The remainder of this paper is organized as follow. In Section~\ref{sec:relWork}, we describe several areas related work. Section~\ref{sec:design} and Section~\ref{sec:implementation} describe the design and implementation of our query assignment method. Section~\ref{sec:experiments} describes the experimental evaluation of our method and Section~\ref{sec:discussion} discusses the results of the experiments as well as some of our limitations and future work. Section~\ref{sec:conclusion} finishes with some concluding remarks.

\section{Related Work}
\label{sec:relWork}

To work around this problem, many researchers focus on estimating workload resource usage in order to maximal performance while minimizing the cost of resources used~\cite{citeulike:6656217,5452742,curino2011relational, MIT-Relational}. This predict job execution time and resource requirements technique can help cloud provider to make decision about which requests from which users are to be executed on which computational resources, and when~\cite{citeulike:6656217}. Many researchers had built workload placement recommendation service base on workload demand patterns~\cite{Gmach:2007:WAD:1524302.1524818, Atikoglu:2012:WAL:2254756.2254766}, and such approach can result in 35\% reduction in processor usage~\cite{Gmach:2007:WAD:1524302.1524818}. Differ to our study, our system do not take workload requirement perdition into account, because we believe that execute workload analysis for every query will result in some latency issues. Instead, our system focuses on dynamically forwarding workload to the idlest server, in order to prevent hotspot.
 
Furthermore, some other researchers focus on partitioning schemes. Works like graph partitioning algorithms~\cite{Karypis:1998:FHQ:305219.305248}, workload-aware partitioning~\cite{Scholl:2009:WDP:1516360.1516366}, and classical work on physical design and partitioning~\cite{Zilio:1998:PDD:928651} are focusing on dividing data into partitions that maximize transaction/query performance to allow workloads to scale across multiple computing nodes. However, graph partitioning is NP-hard problems, and solutions to this problem are generally derived using heuristics and approximation algorithms~\cite{citeulike:11192678}, and we believe that this will introduce execution complexity, and the performance is vary to different databases. Next, the workload-aware partitioning focus on partition tables base on workload prediction~\cite{Scholl:2009:WDP:1516360.1516366, Mit-Shinobi}; however, there are many workloads, a Ô¨Ånite number can be hosted by each server, and each workload has capacity requirements that may frequently change based on business needs~\cite{Gmach:2007:WAD:1524302.1524818}, this means that workload-aware partitioning needs to be dynamic rather than static; however dynamic workload-aware partitioning will reduce performance dramatically. Last, some other works on physical design and partitioning allows database loaded into the system by both static decision and dynamic decision in order to increase I/O bandwidth~\cite{Zilio:1998:PDD:928651}. This approach is pragmatic, but if we only rely on partitioning database the performance will be limited.
 
Virtual machine (VM) migration is also another approach for load balancing. VM migration focuses on the transfer of a VM from one physical machine to another with little or no service downtime (e.g. live VM migration) when the server that the VM sits on becomes overloaded with processes, traffic, or memory usage~\cite{Clark:2005:LMV:1251203.1251223}. Nevertheless, the challenges with long distance live migration are the WAN bandwidth, latency, and packet loss limitations that are outside the control of most IT organizations. Many applications are susceptible to network issues across the WAN that can be exacerbated by distance and network quality~\cite{murphyVMWare}, in addition, traditional VM migration will cause network traffic and bandwidth consumption, and many VM migration researcher are struggling in mitigating those causes~\cite{Liu:2009:LMV:1551609.1551630}.
